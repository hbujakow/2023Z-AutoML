{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done downloading\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    file_path_train = \"artificial_train.data\"\n",
    "\n",
    "    df_train = pd.read_csv(file_path_train, sep=\" \", header=None)\n",
    "    df_train = df_train.drop(df_train.columns[-1], axis=1)\n",
    "\n",
    "    X_train = df_train\n",
    "\n",
    "    file_path_test = \"artificial_test.data\"\n",
    "\n",
    "    df_test = pd.read_csv(file_path_test, sep=\" \", header=None)\n",
    "    df_test = df_test.drop(df_test.columns[-1], axis=1)\n",
    "\n",
    "    X_test = df_test\n",
    "\n",
    "    file_path_train_labels = \"artificial_train.labels\"\n",
    "\n",
    "    df_train_labels = pd.read_csv(file_path_train_labels, sep=\" \", header=None)\n",
    "\n",
    "    y_train = df_train_labels\n",
    "\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "X_train, y_train, X_test = get_data()\n",
    "\n",
    "print(f\"Done downloading\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy dla ręcznego modelu: 0.6539115646258504\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Klasyfikacja przy użyciu RandomForest\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "X_train_raw, y_train_raw, X_test_raw = get_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_raw, y_train_raw, test_size=0.2, random_state=54)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_val_pred_rf = rf_classifier.predict(X_val)\n",
    "\n",
    "balanced_accuracy_rf = balanced_accuracy_score(y_val, y_val_pred_rf)\n",
    "print(f\"Balanced Accuracy dla ręcznego modelu: {balanced_accuracy_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy dla modelu z komitetu: 0.725890356142457\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Tworzenie komitetu modeli\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=54)\n",
    "svm_classifier = SVC(probability=True, random_state=54)\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "estimators=[('rf', rf_classifier), ('gb', gb_classifier), ('svm', svm_classifier)],voting='soft'\n",
    ")\n",
    "\n",
    "voting_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_val_pred_voting = voting_classifier.predict(X_val)\n",
    "\n",
    "balanced_accuracy_voting = balanced_accuracy_score(y_val, y_val_pred_voting)\n",
    "print(f\"Balanced Accuracy dla modelu z komitetu: {balanced_accuracy_voting}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy dla modelu z komitetu z wybranymi cechami: 0.8004201680672269\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Wybór najważniejszych cech za pomocą RandomForest\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "sfm = SelectFromModel(rf_classifier, max_features=50)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train.values.ravel())\n",
    "X_val_selected = sfm.transform(X_val)\n",
    "\n",
    "rf_classifier_selected = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "gb_classifier_selected = GradientBoostingClassifier(n_estimators=100, random_state=54)\n",
    "svm_classifier_selected = SVC(probability=True, random_state=54)\n",
    "\n",
    "voting_classifier_selected = VotingClassifier(\n",
    "    estimators=[('rf', rf_classifier_selected), ('gb', gb_classifier_selected), ('svm', svm_classifier_selected)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_classifier_selected.fit(X_train_selected, y_train.values.ravel())\n",
    "\n",
    "y_val_pred_voting_selected = voting_classifier_selected.predict(X_val_selected)\n",
    "\n",
    "balanced_accuracy_voting_selected = balanced_accuracy_score(y_val, y_val_pred_voting_selected)\n",
    "print(f\"Balanced Accuracy dla modelu z komitetu z wybranymi cechami: {balanced_accuracy_voting_selected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 10, Balanced Accuracy: 0.8202280912364945\n",
      "Num Features: 20, Balanced Accuracy: 0.8401360544217688\n",
      "Num Features: 30, Balanced Accuracy: 0.825530212084834\n",
      "Num Features: 40, Balanced Accuracy: 0.8155262104841936\n",
      "Num Features: 50, Balanced Accuracy: 0.8004201680672269\n",
      "Num Features: 60, Balanced Accuracy: 0.8053221288515406\n",
      "Num Features: 70, Balanced Accuracy: 0.7753101240496199\n",
      "Num Features: 80, Balanced Accuracy: 0.78531412565026\n",
      "Num Features: 90, Balanced Accuracy: 0.7804121648659463\n",
      "Num Features: 100, Balanced Accuracy: 0.7903161264505802\n",
      "Num Features: 110, Balanced Accuracy: 0.7655062024809924\n",
      "Num Features: 120, Balanced Accuracy: 0.7731592637054823\n",
      "Num Features: 130, Balanced Accuracy: 0.7560024009603842\n",
      "Num Features: 140, Balanced Accuracy: 0.7431472589035615\n",
      "Num Features: 150, Balanced Accuracy: 0.738345338135254\n",
      "Num Features: 160, Balanced Accuracy: 0.7507002801120448\n",
      "Num Features: 170, Balanced Accuracy: 0.7507002801120448\n",
      "Num Features: 180, Balanced Accuracy: 0.7507002801120448\n",
      "Num Features: 190, Balanced Accuracy: 0.7507002801120448\n",
      "Num Features: 200, Balanced Accuracy: 0.7507002801120448\n",
      "Najlepsza ilość cech: 20\n",
      "Balanced Accuracy dla modelu z komitetu z najlepszymi cechami: 0.8401360544217688\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Optymalizacja ilości cech\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=54)\n",
    "svm_classifier = SVC(probability=True, random_state=54)\n",
    "\n",
    "max_features_to_try = 200\n",
    "step = 10\n",
    "\n",
    "best_balanced_accuracy = 0\n",
    "best_num_features = 0\n",
    "\n",
    "for num_features in range(10, max_features_to_try + 1, step):\n",
    "    sfm = SelectFromModel(rf_classifier, max_features=num_features)\n",
    "    X_train_selected = sfm.fit_transform(X_train, y_train.values.ravel())\n",
    "    X_val_selected = sfm.transform(X_val)\n",
    "\n",
    "    voting_classifier_selected = VotingClassifier(\n",
    "        estimators=[('rf', rf_classifier), ('gb', gb_classifier), ('svm', svm_classifier)],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    voting_classifier_selected.fit(X_train_selected, y_train.values.ravel())\n",
    "\n",
    "    y_val_pred_voting_selected = voting_classifier_selected.predict(X_val_selected)\n",
    "\n",
    "    balanced_accuracy_voting_selected = balanced_accuracy_score(y_val, y_val_pred_voting_selected)\n",
    "\n",
    "    print(f\"Num Features: {num_features}, Balanced Accuracy: {balanced_accuracy_voting_selected}\")\n",
    "\n",
    "    if balanced_accuracy_voting_selected > best_balanced_accuracy:\n",
    "        best_balanced_accuracy = balanced_accuracy_voting_selected\n",
    "        best_num_features = num_features\n",
    "\n",
    "print(f\"Najlepsza ilość cech: {best_num_features}\")\n",
    "print(f\"Balanced Accuracy dla modelu z komitetu z najlepszymi cechami: {best_balanced_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 15, Balanced Accuracy: 0.8326830732292917\n",
      "Num Features: 16, Balanced Accuracy: 0.8301320528211285\n",
      "Num Features: 17, Balanced Accuracy: 0.8401360544217688\n",
      "Num Features: 18, Balanced Accuracy: 0.842687074829932\n",
      "Num Features: 19, Balanced Accuracy: 0.8424869947979192\n",
      "Num Features: 20, Balanced Accuracy: 0.8401360544217688\n",
      "Num Features: 21, Balanced Accuracy: 0.8450380152060825\n",
      "Num Features: 22, Balanced Accuracy: 0.8352340936374549\n",
      "Num Features: 23, Balanced Accuracy: 0.8353341336534614\n",
      "Num Features: 24, Balanced Accuracy: 0.8306322529011605\n",
      "Num Features: 25, Balanced Accuracy: 0.8407362945178072\n",
      "Najlepsza ilość cech: 21\n",
      "Balanced Accuracy dla modelu z komitetu z najlepszymi cechami: 0.8450380152060825\n"
     ]
    }
   ],
   "source": [
    "# 2.5 Rozszerzona optymalizacja cech\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=54)\n",
    "svm_classifier = SVC(probability=True, random_state=54)\n",
    "\n",
    "assert(best_num_features > 5)\n",
    "\n",
    "max_features_to_try_second = best_num_features + 5\n",
    "min_feature_to_try_second = best_num_features - 5\n",
    "step = 1\n",
    "\n",
    "best_balanced_accuracy_second = 0\n",
    "best_num_features_second = 0\n",
    "\n",
    "for num_features in range(min_feature_to_try_second, max_features_to_try_second + 1, step):\n",
    "    sfm = SelectFromModel(rf_classifier, max_features=num_features)\n",
    "    X_train_selected = sfm.fit_transform(X_train, y_train.values.ravel())\n",
    "    X_val_selected = sfm.transform(X_val)\n",
    "\n",
    "    voting_classifier_selected = VotingClassifier(\n",
    "        estimators=[('rf', rf_classifier), ('gb', gb_classifier), ('svm', svm_classifier)],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    voting_classifier_selected.fit(X_train_selected, y_train.values.ravel())\n",
    "\n",
    "    y_val_pred_voting_selected = voting_classifier_selected.predict(X_val_selected)\n",
    "\n",
    "    balanced_accuracy_voting_selected = balanced_accuracy_score(y_val, y_val_pred_voting_selected)\n",
    "\n",
    "    print(f\"Num Features: {num_features}, Balanced Accuracy: {balanced_accuracy_voting_selected}\")\n",
    "\n",
    "    if balanced_accuracy_voting_selected > best_balanced_accuracy_second:\n",
    "        best_balanced_accuracy_second = balanced_accuracy_voting_selected\n",
    "        best_num_features_second = num_features\n",
    "\n",
    "print(f\"Najlepsza ilość cech: {best_num_features_second}\")\n",
    "print(f\"Balanced Accuracy dla modelu z komitetu z najlepszymi cechami: {best_balanced_accuracy_second}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 21, Balanced Accuracy: 0.8700480192076832\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Końcowy model\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=54)\n",
    "svm_classifier = SVC(probability=True, random_state=54)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=100, random_state=54)\n",
    "\n",
    "num_features = best_num_features_second\n",
    "et_classifier.fit(X_train, y_train.values.ravel())\n",
    "sfm = SelectFromModel(et_classifier, max_features=num_features)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train.values.ravel())\n",
    "X_val_selected = sfm.transform(X_val)\n",
    "\n",
    "voting_classifier_selected = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('gb', gb_classifier),\n",
    "        ('svm', svm_classifier),\n",
    "        ('knn', knn_classifier),\n",
    "        ('et', et_classifier)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_classifier_selected.fit(X_train_selected, y_train.values.ravel())\n",
    "\n",
    "y_val_pred_voting_selected = voting_classifier_selected.predict(X_val_selected)\n",
    "\n",
    "balanced_accuracy_voting_selected = balanced_accuracy_score(y_val, y_val_pred_voting_selected)\n",
    "\n",
    "print(f\"Num Features: {num_features}, Balanced Accuracy: {balanced_accuracy_voting_selected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected = sfm.transform(X_test_raw)\n",
    "\n",
    "test_predictions = voting_classifier_selected.predict(X_test_selected)\n",
    "\n",
    "test_probabilities = voting_classifier_selected.predict_proba(X_test_selected)\n",
    "positive_class_probabilities = test_probabilities[:, 1]\n",
    "\n",
    "with open('predictions.txt', 'w') as file:\n",
    "    for prob in positive_class_probabilities:\n",
    "        file.write(f\"{prob}\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
